{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/lryne3Nc4ak9GzXVF8Hq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemamalini625/youtube-harvesting-project/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbgViKXBdck"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "from googleapiclient.discovery import build\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "import httplib2\n",
        "import requests\n",
        "import streamlit as st\n",
        "import googleapiclient.discovery\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from pymongo import MongoClient\n",
        "from googleapiclient.errors import HttpError\n",
        "from datetime import datetime\n",
        "import google.auth\n",
        "import pymongo\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#  Data Extraction from 5 different youtube Channels with my API key:\n",
        "\n",
        "api_key= \"AIzaSyBhq9db_KumO5vbwfW2gd_uz7ONHDB2G_Y\"\n",
        "ch_ids= [\"UCiT9RITQ9PW6BhXK0y2jaeg\",# ken jee\n",
        "         \"UCiEmtpFVJjpvdhsQ2QAhxVA\",# zen class from guvi\n",
        "         \"UCduIoIMfD8tT3KoU0-zBRgQ\",#guvi\n",
        "         \"UCSJbGtTlrDami-tDGPUV9-w\",#Academind\n",
        "         \"UCWv7vMbMWH4-V0ZXdmDpPBA\"#programming with mosh\n",
        "\n",
        "         ]\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "\n",
        "#Extracting 5 channel details of their Name, Description,Join date,Subscriber ,Viewers and Videocount\n",
        "\n",
        "def get_channel(youtube,ch_ids):\n",
        "\n",
        "    whole_data=[]\n",
        "\n",
        "    request = youtube.channels().list(part=\"snippet,contentDetails,statistics\",\n",
        "                                      id=','.join(ch_ids))\n",
        "    response = request.execute()\n",
        "\n",
        "    for i in range (len(response['items'])):\n",
        "\n",
        "      channel=dict( ch_name=response['items'][i]['snippet']['title'] ,# channel title,\n",
        "                    ch_desc=response['items'][i]['snippet']['description'], #channel description\n",
        "                    ch_join=response['items'][i]['snippet']['publishedAt'],#channel started\n",
        "                    subscriber=response['items'][i]['statistics']['subscriberCount'],#subscriber count\n",
        "                    viewer=response['items'][i]['statistics']['viewCount'],#view count\n",
        "                    vi_count=response['items'][i]['statistics']['videoCount'],\n",
        "                    playlist_id=response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])# video count)\n",
        "      whole_data.append(channel)\n",
        "    return whole_data\n",
        "\n",
        "channel_details=get_channel(youtube,ch_ids)\n",
        "channel_details\n",
        "about_channel=pd.DataFrame(channel_details)\n",
        "about_channel\n",
        "about_channel.dtypes\n",
        "about_channel['subscriber']=pd.to_numeric(about_channel['subscriber'])\n",
        "about_channel['viewer']=pd.to_numeric(about_channel['viewer'])\n",
        "about_channel['vi_count']=pd.to_numeric(about_channel['vi_count'])\n",
        "about_channel['ch_join']=pd.to_datetime(about_channel['ch_join'])\n",
        "about_channel.dtypes\n",
        "\n",
        "# extracting playlist id for particular KEN JEE channel\n",
        "playlist_ids=about_channel.loc[about_channel['ch_name'] == 'Ken Jee' ,'playlist_id'].iloc[0]\n",
        "def get_video(youtube,playlist_ids):\n",
        "\n",
        "      request = youtube.playlistItems().list(part='contentDetails',playlistId=playlist_ids,maxResults = 50)\n",
        "      response = request.execute()\n",
        "\n",
        "      video_ids=[]\n",
        "      for i in range(len(response ['items'])):\n",
        "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
        "\n",
        "      next_page_token = response.get('nextPageToken')\n",
        "      more_pages = True\n",
        "\n",
        "      while more_pages:\n",
        "            if next_page_token is None:\n",
        "                more_pages = False\n",
        "            else:\n",
        "                request = youtube.playlistItems().list(part='contentDetails',playlistId=playlist_ids,maxResults = 50,pageToken =next_page_token )\n",
        "                response = request.execute()\n",
        "                for i in range(len(response ['items'])):\n",
        "                    video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
        "                next_page_token = response.get('nextPageToken')\n",
        "      return video_ids\n",
        "video_ids=get_video(youtube,playlist_ids)\n",
        "video_ids\n",
        "def get_video(youtube,video_ids):\n",
        "  all_video=[]\n",
        "  for i in range(0,len(video_ids),50):\n",
        "      request = youtube.videos().list(part='snippet,statistics',\n",
        "                                    id =','.join(video_ids[i:i+50]))\n",
        "      response=request.execute()\n",
        "      for video in response['items']:\n",
        "          video_status=dict(video_title=video['snippet']['title'],\n",
        "                            published = video['snippet']['publishedAt'],\n",
        "                            viewcount = video['statistics']['viewCount'],\n",
        "                            comment_ct = video['statistics']['commentCount'],\n",
        "                            likecount = video['statistics']['likeCount'])\n",
        "\n",
        "\n",
        "          all_video.append(video_status)\n",
        "  return all_video\n",
        "\n",
        "#Extracting video details of all the videos in the particular channel and the respective details of each video:\n",
        "\n",
        "video_det=get_video(youtube,video_ids)\n",
        "video_data=pd.DataFrame(video_det)\n",
        "video_data\n",
        "video_data['published'] = pd.to_datetime(video_data['published']).dt.date\n",
        "video_data['viewcount'] = pd.to_numeric(video_data['viewcount'])\n",
        "video_data['likecount'] = pd.to_numeric(video_data['likecount'])\n",
        "video_data['comment_ct'] = pd.to_numeric(video_data['comment_ct'])\n",
        "video_det\n",
        "\n",
        "\n",
        "#Inserting channel details and video details into Mongo DB as 2 collections to export into json format\n",
        "# DATABASE  NAME : youtube_project\n",
        "# COLLECTIONS NAME : channel_list.json ,videoslist.json\n",
        "\n",
        "\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient('mongodb://localhost:27017/')\n",
        "db = client['youtube_project']\n",
        "collection = db['channel_list']\n",
        "collection = db['videoslist']\n",
        "\n",
        "# Insert channel data into MongoDB\n",
        "collection.insert_many(channel_details)\n",
        "\n",
        "# Insert video data into MongoDB\n",
        "collection.insert_many(video_det)\n",
        "\n",
        "# 2.json files are uploaded in the repository for the reference\n",
        "\n",
        "\n",
        "# sql query to dump the json file into my sql\n",
        "\n",
        "#  1.inserting channellist json file into mysql\n",
        "declare @json_data varchar(max)\n",
        "\n",
        "select @json_data = BulkColumn\n",
        "\n",
        "from openrowset\n",
        "\n",
        "(\n",
        "\tBULK 'C:\\Users\\Hema Chandran\\Desktop\\python trial\\youtube proj\\channel_list.json ' , SINGLE_CLOB\n",
        "\n",
        ") as datasource\n",
        "\n",
        "print @json_data\n",
        "select * from openjson(@json_data)\n",
        "WITH\n",
        "(\n",
        "\tch_name varchar(20),\n",
        "\tch_desc varchar(20),\n",
        "\tch_join date,\n",
        "\n",
        "\tsubscriber int ,\n",
        "\tvi_count int,\n",
        "\tplaylist_id varchar(20),\n",
        "\tvideo_ids varchar(20),\n",
        "\tviewer int\n",
        "\n",
        ")\n",
        "insert into emp2( emp2_ch_name, emp2_ch_desc, emp2_ch_join,emp2_subscriber,emp2_vi_count,emp2_playlist_id,emp2_video_ids,emp2_viewer)\n",
        "select ch_name,ch_desc,ch_join,subscriber,vi_count,playlist_id,video_ids,viewer from openjson (@json_data)\n",
        "WITH\n",
        "(\n",
        "\n",
        "\tch_name varchar(20),\n",
        "\tch_desc varchar(20),\n",
        "\tch_join date,\n",
        "\tsubscriber int ,\n",
        "\tvi_count int,\n",
        "\tplaylist_id varchar(20),\n",
        "\tvideo_ids varchar(20),\n",
        "\tviewer int\n",
        "\n",
        ")\n",
        "\n",
        "#2.inserting videoslist json file into mysql\n",
        "declare @json_data varchar(max)\n",
        "\n",
        "select @json_data = BulkColumn\n",
        "\n",
        "from openrowset\n",
        "\n",
        "(\n",
        "\tBULK 'C:\\Users\\Hema Chandran\\Desktop\\python trial\\youtube proj\\youtube_project.videoslist.json ' , SINGLE_CLOB\n",
        "\n",
        ") as datasource\n",
        "\n",
        "print @json_data\n",
        "select * from openjson(@json_data)\n",
        "WITH\n",
        "(\n",
        "\tvideo_title varchar(20),\n",
        "\tpublished date,\n",
        "\tviewcount int,\n",
        "\tcomment_ct int ,\n",
        "\tlikecount int\n",
        "\n",
        ")\n",
        " # Data Migrate to MySQL\n",
        "\n",
        "        # Connect to the MySQL server\n",
        "        connect = mysql.connector.connect(\n",
        "        host = \"localhost\",\n",
        "        user = \"root\",\n",
        "        password = \"root\",\n",
        "        auth_plugin = \"mysql_native_password\")\n",
        "\n",
        "        # Create a new database and use\n",
        "        mycursor = connect.cursor()\n",
        "        mycursor.execute(\"CREATE DATABASE IF NOT EXISTS youtube_db\")\n",
        "\n",
        "        # Close the cursor and database connection\n",
        "        mycursor.close()\n",
        "        connect.close()\n",
        "\n",
        "        # Connect to the new created database\n",
        "        engine = create_engine('mysql+mysqlconnector://root:root@localhost/youtube_db', echo=False)\n",
        "\n",
        "\n",
        "st.header(':[Channel Data Analysis zone]')\n",
        "st.write ('''(Note:- This zone **Analysis of a collection of channel data** depends on your question selection and gives a table format output.)''')\n",
        "\n",
        "# Check available channel data\n",
        "Check_channel = st.checkbox('**Check available channel data for analysis**')\n",
        "\n",
        "if Check_channel:\n",
        "   # Create database connection\n",
        "    engine = create_engine('mysql+mysqlconnector://root:root@localhost/youtube_db', echo=False)\n",
        "    # Execute SQL query to retrieve channel names\n",
        "    query = \"SELECT Ch_name FROM emp2;\"\n",
        "    results = pd.read_sql(query, engine)\n",
        "    # Get channel names as a list\n",
        "    ch_name_fromsql = list(results['Ch_name'])\n",
        "    # Create a DataFrame from the list and reset the index to start from 1\n",
        "    df_at_sql = pd.DataFrame(ch_name_fromsql, columns=['Available channel data']).reset_index(drop=True)\n",
        "    # Reset index to start from 1 instead of 0\n",
        "    df_at_sql.index += 1\n",
        "    # Show dataframe\n",
        "    st.dataframe(df_at_sql)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------     /   Questions   /    ------------------------------------------------------------- #\n",
        "st.subheader(':[Channels Analysis ]')\n",
        "\n",
        "# Selectbox creation\n",
        "question_tosql = st.selectbox('**Select your Question**',\n",
        "('1. What are the names of all the videos and their corresponding channels?',\n",
        "'2. Which channels have the most number of videos, and how many videos do they have?',\n",
        "'3. What are the top 10 most viewed videos and their respective channels?',\n",
        "'4. How many comments were made on each video, and what are their corresponding video names?',\n",
        "'5. Which videos have the highest number of likes, and what are their corresponding channel names?',\n",
        "'6. What is the total number of likes and dislikes for each video, and what are their corresponding video names?',\n",
        "'7. What is the total number of views for each channel, and what are their corresponding channel names?',\n",
        "'8. What are the names of all the channels that have published videos in the year 2022?',\n",
        "'9. What is the average duration of all videos in each channel, and what are their corresponding channel names?',\n",
        "'10. Which videos have the highest number of comments, and what are their corresponding channel names?'), key = 'collection_question')\n",
        "\n",
        "# Creat a connection to SQL\n",
        "connect_for_question = pymysql.connect(host='localhost', user='root', password='root', db='youtube_db')\n",
        "cursor = connect_for_question.cursor()\n",
        "\n",
        "# Q1\n",
        "if question_tosql == '1. What are the names of all the videos and their corresponding channels?':\n",
        "    cursor.execute(\"SELECT emp2.ch_name, empt.video_ids FROM emp2 JOIN playlist JOIN video ON channel.Channel_Id = playlist.Channel_Id AND playlist.Playlist_Id = video.Playlist_Id;\")\n",
        "    result_1 = cursor.fetchall()\n",
        "    df1 = pd.DataFrame(result_1, columns=['Channel Name', 'Video Name']).reset_index(drop=True)\n",
        "    df1.index += 1\n",
        "    st.dataframe(df1)\n",
        "\n",
        "# Q2\n",
        "elif question_tosql == '2. Which channels have the most number of videos, and how many videos do they have?':\n",
        "\n",
        "    col1,col2 = st.columns(2)\n",
        "    with col1:\n",
        "        cursor.execute(\"SELECT ch_name, vi_count FROM emp2 ORDER BY vi_count DESC;\")\n",
        "        result_2 = cursor.fetchall()\n",
        "        df2 = pd.DataFrame(result_2,columns=['Channel Name','Video Count']).reset_index(drop=True)\n",
        "        df2.index += 1\n",
        "        st.dataframe(df2)\n",
        "\n",
        "    with col2:\n",
        "        fig_vc = px.bar(df2, y='Video Count', x='Channel Name', text_auto='.2s', title=\"Most number of videos\", )\n",
        "        fig_vc.update_traces(textfont_size=16,marker_color='#E6064A')\n",
        "        fig_vc.update_layout(title_font_color='#1308C2 ',title_font=dict(size=25))\n",
        "        st.plotly_chart(fig_vc,use_container_width=True)\n",
        "\n",
        "# Q3\n",
        "elif question_tosql == '3. What are the top 10 most viewed videos and their respective channels?':\n",
        "\n",
        "    col1,col2 = st.columns(2)\n",
        "    with col1:\n",
        "        cursor.execute(\"SELECT emp2.ch_Name, emp2.video_ids, emp2.vi_count FROM emp2 JOIN playlist ON channel.Channel_Id = playlist.Channel_Id JOIN video ON playlist.Playlist_Id = video.Playlist_Id ORDER BY video.vi_count DESC LIMIT 10;\")\n",
        "        result_3 = cursor.fetchall()\n",
        "        df3 = pd.DataFrame(result_3,columns=['Channel Name', 'Video Name', 'View count']).reset_index(drop=True)\n",
        "        df3.index += 1\n",
        "        st.dataframe(df3)\n",
        "\n",
        "    with col2:\n",
        "        fig_topvc = px.bar(df3, y='View count', x='Video Name', text_auto='.2s', title=\"Top 10 most viewed videos\")\n",
        "        fig_topvc.update_traces(textfont_size=16,marker_color='#E6064A')\n",
        "        fig_topvc.update_layout(title_font_color='#1308C2 ',title_font=dict(size=25))\n",
        "        st.plotly_chart(fig_topvc,use_container_width=True)\n",
        "\n",
        "# Q4\n",
        "elif question_tosql == '4. How many comments were made on each video, and what are their corresponding video names?':\n",
        "    cursor.execute(\"SELECT emp2.Channel_Name, emp2.Video_ids, video.Comment_Count FROM emp2 JOIN playlist ON channel.Channel_Id = playlist.Channel_Id JOIN empt ON playlist.Playlist_Id = video.Playlist_Id;\")\n",
        "    result_4 = cursor.fetchall()\n",
        "    df4 = pd.DataFrame(result_4,columns=['Channel Name', 'Video Name', 'Comment count']).reset_index(drop=True)\n",
        "    df4.index += 1\n",
        "    st.dataframe(df4)\n",
        "\n",
        "# Q5\n",
        "elif question_tosql == '5. Which videos have the highest number of likes, and what are their corresponding channel names?':\n",
        "    cursor.execute(\"SELECT emp2.Ch_name, empt.video_title, empt.likecount FROM emp2 JOIN playlist ON channel.Channel_Id = playlist.Channel_Id JOIN empt ON playlist.Playlist_Id = video.Playlist_Id ORDER BY video.Like_Count DESC;\")\n",
        "    result_5= cursor.fetchall()\n",
        "    df5 = pd.DataFrame(result_5,columns=['Channel Name', 'Video Name', 'Like count']).reset_index(drop=True)\n",
        "    df5.index += 1\n",
        "    st.dataframe(df5)\n",
        "\n",
        "# Q6\n",
        "elif question_tosql == '6. What is the total number of likes and dislikes for each video, and what are their corresponding video names?':\n",
        "    st.write('**Note:- In November 2021, YouTube removed the public dislike count from all of its videos.**')\n",
        "    cursor.execute(\"SELECT emp2.ch_name, empt.video_title, empt.likecount, empt.Dislike_Count FROM emp2 JOIN playlist ON channel.Channel_Id = playlist.Channel_Id JOIN empt ON playlist.Playlist_Id = video.Playlist_Id ORDER BY empt.likecount DESC;\")\n",
        "    result_6= cursor.fetchall()\n",
        "    df6 = pd.DataFrame(result_6,columns=['Channel Name', 'Video Name', 'Like count','Dislike count']).reset_index(drop=True)\n",
        "    df6.index += 1\n",
        "    st.dataframe(df6)\n",
        "\n",
        "# Q7\n",
        "elif question_tosql == '7. What is the total number of views for each channel, and what are their corresponding channel names?':\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        cursor.execute(\"SELECT ch_name,vi_count FROM emp2 ORDER BY vi_count DESC;\")\n",
        "        result_7= cursor.fetchall()\n",
        "        df7 = pd.DataFrame(result_7,columns=['Channel Name', 'Total number of views']).reset_index(drop=True)\n",
        "        df7.index += 1\n",
        "        st.dataframe(df7)\n",
        "\n",
        "    with col2:\n",
        "        fig_topview = px.bar(df7, y='Total number of views', x='Channel Name', text_auto='.2s', title=\"Total number of views\", )\n",
        "        fig_topview.update_traces(textfont_size=16,marker_color='#E6064A')\n",
        "        fig_topview.update_layout(title_font_color='#1308C2 ',title_font=dict(size=25))\n",
        "        st.plotly_chart(fig_topview,use_container_width=True)\n",
        "\n",
        "# Q8\n",
        "elif question_tosql == '8. What are the names of all the channels that have published videos in the year 2022?':\n",
        "    cursor.execute(\"SELECT emp2.Ch_name, empt.video_title, empt.published FROM emp2 JOIN playlist ON channel.Channel_Id = playlist.Channel_Id JOIN empt ON playlist.Playlist_Id = video.Playlist_Id  WHERE EXTRACT(YEAR FROM Published) = 2022;\")\n",
        "    result_8= cursor.fetchall()\n",
        "    df8 = pd.DataFrame(result_8,columns=['Channel Name','Video Name', 'Year 2022 only']).reset_index(drop=True)\n",
        "    df8.index += 1\n",
        "    st.dataframe(df8)\n",
        "\n",
        "# Q9\n",
        "elif question_tosql == '9. What is the average duration of all videos in each channel, and what are their corresponding channel names?':\n",
        "    cursor.execute(\"SELECT emp2.ch_name, TIME_FORMAT(SEC_TO_TIME(AVG(TIME_TO_SEC(TIME(video.Duration)))), '%H:%i:%s') AS duration  FROM emp2 JOIN playlist ON emp2.Channel_Id = playlist.Channel_Id JOIN empt ON playlist.Playlist_Id = video.Playlist_Id GROUP by ch_name ORDER BY duration DESC ;\")\n",
        "    result_9= cursor.fetchall()\n",
        "    df9 = pd.DataFrame(result_9,columns=['Channel Name','Average duration of videos (HH:MM:SS)']).reset_index(drop=True)\n",
        "    df9.index += 1\n",
        "    st.dataframe(df9)\n",
        "\n",
        "# Q10\n",
        "elif question_tosql == '10. Which videos have the highest number of comments, and what are their corresponding channel names?':\n",
        "    cursor.execute(\"SELECT emp2.ch_name, empt.video_title, empt.comment_ct FROM channel JOIN playlist ON channel.Channel_Id = playlist.Channel_Id JOIN empt ON playlist.Playlist_Id = video.Playlist_Id ORDER BY empt.comment_Ct DESC;\")\n",
        "    result_10= cursor.fetchall()\n",
        "    df10 = pd.DataFrame(result_10,columns=['Channel Name','Video Name', 'Number of comments']).reset_index(drop=True)\n",
        "    df10.index += 1\n",
        "    st.dataframe(df10)\n",
        "\n",
        "# SQL DB connection close\n",
        "connect_for_question.close()\n"
      ]
    }
  ]
}